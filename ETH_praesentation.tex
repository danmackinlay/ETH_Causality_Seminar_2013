% !TEX TS-program = pdflatex
% !TEX encoding = Isolatin

% Copyright Marius Hofert, Markus Kohm
% changed by D. Hennig, IT-Service ETH

%% Version 1.4 09.05.2011
%\input{ETH_res/ETH_packages.tex} % docymentsyle and packages
\input{ETH_packages.tex} % docymentsyle and packages
%\input{ETH_res/ETH_settings.tex} % settings
\input{ETH_settings.tex} % settings

% ====  colors  ================================================================
\definecolor{ETHblue}{RGB}{51,89,148}           % #335994
\definecolor{ETHlightblue}{RGB}{114,129,192}    % for Department-Logo
\definecolor{ETHtitleblue}{RGB}{0,49,91}        % for title (#00315b)
\definecolor{ETHbrown}{RGB}{148,116,51}
\definecolor{ETHred}{RGB}{161,82,71}
\definecolor{ETHdarkgray}{rgb}{0.282,0.322,0.361}    % for box (#48525c)
\newcommand*{\ETHblue}[1]{\textcolor{ETHblue}{#1}}
\newcommand*{\ETHlightblue}[1]{\textcolor{ETHlightblue}{#1}}
\newcommand*{\ETHtitleblue}[1]{\textcolor{ETHtitleblue}{#1}}
\newcommand*{\ETHbrown}[1]{\textcolor{ETHbrown}{#1}}
\newcommand*{\ETHred}[1]{\textcolor{ETHred}{#1}}
\newcommand*{\ETHdarkgray}[1]{\textcolor{ETHdarkgray}{#1}}

% ==== document related info ===================================================
\newcommand*{\ETHdeptshort}{\textsc {\color{ETHlightblue}D}\,MATH}
\newcommand*{\ETHdeptlong}{Department of Mathematics}
\newcommand*{\ETHinstitut}{Seminar for Statistics}
\newcommand*{\ETHtitle}{A Non-Parametric Independence Test}
\newcommand*{\ETHsubtitle}{The Hilbert-Schmidt Independence Criterion}
\newcommand*{\ETHauthor}{D MacKinlay, C. Pelloni, A. Toletti / \ETHdeptlong / \ETHinstitut}
\newcommand*{\ETHdate}{Monday, 24th April 2013}

% ==== document language =======================================================
% American English
\usepackage[american]{babel}
%\selectlanguage{american}

% we want these for nice mathematical typesetting
\usepackage{amssymb,amsmath,amsthm,bbm,mathtools}
\newtheorem*{defn}{Definition}
\newtheorem*{fact}{Fact}

%\AtBeginDocument{\renewcaptionname{american}{\contentsname}{\large Outline}}% toc-name

% ==== document ================================================================
\begin{document}
% ==============================================================================
% titlepage 1
% background picture
\begin{tikzpicture}[overlay]
    \node [shift={(-69.5mm,-133.95mm)}]  at (current page.north east)
    %% ETH-Hauptgebaeude (main building of the ETH)
%    {\includegraphics[width=\paperwidth]{ETH_res/ETH_HG.jpg}};
    {\includegraphics[width=\paperwidth]{ETH_HG.jpg}};
\end{tikzpicture}%
% content title
\begin{flushright}
    %\vspace{-7mm}
    %{\bfseries\Large\ETHtitle\par}
\end{flushright}
	\vspace{-46.5mm}
	{\bfseries\Large{\color{ETHtitleblue}\ETHtitle}}\par
    \vspace{-3.5mm}
    \Large\ETHsubtitle
\clearpage
\vspace*{-16.5mm}
\tableofcontents
\clearpage
% ==============================================================================

%#### Please fill in your normal Latex document and add some clearpage-commands.
\section{What are we doing today?}

Presenting a non-parametric independence test.

Here are the steps

\begin{enumerate}
	\item Explain why we bother
	\item Present necessary functional analysis background,
	\item Actually derive the test (in two different ways), then,
	\item Construct estimator from data
\end{enumerate}

\clearpage

\section{Why we bother}

\begin{enumerate}
	\item Last week we saw the PC and IC algorithms for inferring the DAG \ldots 
	\item \ldots by estimating pairwise conditional independence\ldots
	\item \ldots from samples of the joint distribution \ldots
	\item \ldots using the \emph{partial correlation} test to infer conditional independence
\end{enumerate}
\clearpage
\dots but partial correlation algorithm only works for linearly additive, Gaussian noise.
\clearpage

Consider:
\begin{enumerate}
\item Categorical data \emph{(If it's raining/if the sprinkler is on/\ldots)}
\item Non-gaussian noise \emph{(e.g. exponential)}
\item Non-additive coupling \emph{(e.g. multiplicative)}
\item Whatever combination of exotic data types, noise and interactions that you would like\dots \emph{(Nucleotide sequences..?)}
\end{enumerate}
\clearpage

Therefore: More general tests are desirable.

Why not non-parametric tests?

\clearpage

What independence tests can relax the strong assumptions of partial correlation?

There are many! e.g. mutual information, rank statistics, copula measures\ldots

\clearpage
Today:

The \emph{Hilbert Schmidt Independence Criterion (HSIC)}

A ``kernelisation''-based~\footnote{as made famous by Support Vector Machines} method, has attractive features.
\begin{enumerate}
\item It can handle arbitrary input spaces, not just $\mathbb{R}^d$ (e.g. nucleotide strings, sprinkler settings)
\item It is natural to conditionalize.
\end{enumerate}
\clearpage
NB: Today we will only construct the marginal (unconditional) independence measure on $\mathcal{X}=\mathbb{R}^d$, by way of introduction. (Homework: conditional estimator on general input spaces.)
\clearpage

Examples
\emph{TODO}

Constructing HSIC

\clearpage
\section{Functional analysis in 15 minutes}
We want to transform our arbitrary data into a natural ``feature'' space with convenient representations of relations between data.

Functional analysis gives us the \emph{Hilbert space}, which formalises this.

\clearpage
\begin{defn}
A Hilbert space $\mathcal{H}$ is a vector space with an inner product $\langle\cdot,\cdot\rangle: \mathcal{H}\times\mathcal{H} \rightarrow\mathbb{R}$.
\end{defn}

Additional technical requirement: It is \emph{complete}.

Additional functional analysis ``twist'': It need not be a finite dimensional vector space.
\clearpage
\begin{defn}
An \emph{inner product}, $\langle\cdot,\cdot\rangle$ on a Hilbert space generalises the definition on $\mathbb{R}^d$.

For $f,\,g$ and $h \in \mathcal{H}$ and for $\alpha$ and $\beta \in \mathbb{R}$:
\begin{enumerate}
\item $\langle\alpha f + \beta g, h\rangle = \alpha\langle f, h\rangle + \beta\langle g, h\rangle$
\item $\langle f, g\rangle = \langle g, f \rangle$
\item $\langle f, f \rangle \ge 0$ and $\langle f, f\rangle = 0$ iff $f =0$
\end{enumerate}
\end{defn}

\clearpage

So we have defined some operations in this feature space.

But our data does not come from such as space.

Let's consider the ``input'' space $\mathcal{X}\ne\mathcal{H}$, and points $x_i \in \mathcal{X}$ drawn from it.

We will use \emph{kernel} functions to relate them.
\clearpage
We define define a \emph{kernel}, $k$,
\begin{equation*}
k : \mathcal{X} \times \mathcal{X} \rightarrow \mathbb{R}
\end{equation*}
and a map
\begin{equation}
\phi: \mathcal{X} \rightarrow \mathcal{H}
\end{equation}
such that 
\begin{equation*}
k(x, x') = \langle \phi(x), \phi(x') \rangle
\end{equation*}
\clearpage
\begin{defn}
A function 
\begin{equation*}
k:\mathcal{X} \times \mathcal{X}\rightarrow \mathbb{R}
\end{equation*}
 is \emph{positive definite} if,
for all $n \ge 1$,
for all $(a_1, a_2, \ldots, a_n) \in \mathbb{R}^n$ and
for all $(x_1, x_2, \ldots, x_n) \in \mathcal{X}^n$,
\begin{equation*}
\sum_{i=1}^n\sum_{j=1}^n a_i a_j k(x_i, x_j) \ge 0
\end{equation*}
\end{defn}
\clearpage
\begin{fact}
Take $\mathcal{H}$ any Hilbert space, and 
\begin{equation*}
\phi: \mathcal{X} \rightarrow \mathcal{H}
\end{equation*}
Then  
\begin{equation*}
k(x, x') = \langle \phi(x), \phi(x') \rangle
\end{equation*}
is a positive definite function.
\end{fact}
But the converse also holds.
\clearpage
\begin{fact}
Take a positive definite function $k : \mathcal{X} \times \mathcal{X} \rightarrow \mathbb{R}$.
Then, there exists a Hilbert space $\mathcal{H}$, and mapping
\begin{equation*}
\phi: \mathcal{X} \rightarrow \mathcal{H}
\end{equation*}
 such that
 \begin{equation*}
 k(x, x') = \langle \phi(x), \phi(x') \rangle
 \end{equation*}
is a positive definite function.
\end{fact}
\clearpage
Therefore:

Given a kernel, we can use it calculate an inner-product between a transformed version of points $x \in \mathcal{X}$ in some \emph{implicit} Hilbert space.

Indeed, $\mathcal{H}$ can be strange indeed.
\clearpage
\subsection*{Reproducing Kernel Hilbert Space (RKHS)}
We impose some additional, useful structure.

Hilbert space of functions
\begin{equation*}
f: \mathcal{X} \rightarrow \mathbb{R}
\end{equation*}
 and 
\begin{equation*}
\forall x \in \mathcal{X}, k(\cdot, x) \in \mathcal{H}
\end{equation*}
(A space of functions \emph{on} $\mathcal{X}$.)
\clearpage
Moreover,  require the \emph{reproducing property}
\begin{align*}
\forall f \in \mathcal{H}, \forall x \in \mathcal{X},\\
\langle f, k(\cdot,x)\rangle = f(x)\rangle
\end{align*}
In such spaces we have that 
\begin{equation*}
k(x,y) = \langle k(\cdot, x), k(\cdot, y) \rangle
\end{equation*}
\clearpage
That is, our kernel $k$ induces the following $\phi$-mapping
\begin{equation*}
\phi: \begin{matrix}
        \mathcal{X}  &\rightarrow \mathcal{H}\\
        x &\mapsto k(x,\cdot)
        \end{matrix}
\end{equation*}
\clearpage
Example kernels on $x, y \in \mathbb{R}^d$
\begin{enumerate}
\item linear kernel \[k(x, y) = x^Ty\]
\item polynomial kernel of degree $d\in \mathbb{N}$: \[k(x, y) = (x^Ty)^d\]
\item Gaussian kernel of bandwidth $\sigma>0$, \[k(x,y) = \exp\left(-\frac{(x-y)^T(x-y)}{2\sigma^2}\right)\]
\end{enumerate}
\clearpage
We will use the Gaussian kernel again.

Nice, intuitive, properties for demonstration.

\begin{itemize}
\item \emph{translation invariant} in $\mathcal{X}=\mathbb{R}^d$
\item measures ``similarity'' between vectors
\end{itemize}
\clearpage
\subsection*{Why bother with this RKHS thing?}

SVM-user's argument:

Take any algorithm that requires only the inner-product of samples.

Now, instead of applying it in the \emph{input space}, apply it in \emph{feature space}.

With a ``good'' kernel function, this can be a flexible feature space, but still be cheap to compute.
\clearpage
Classic algorithms that benefit from this
\begin{enumerate}
\item Support Vector Machines
\item Kernel Principle Component Analysis (\emph{Hauptkomponentenanlayse})
\item Ridge regression
\item Distinguishing between two probability distributions (i.e. the whole point of this presentation)
\end{enumerate}

\subsection*{Distinguishing between two probability distributions}
We use RKHS methods on more ``weird'' objects.

In particular we do kernel comparisons on \emph{probability distributions}.
\clearpage	
Consider a distribution $\mathbb{P}$, with R.V. $\mathcal{X}\sim\mathbb{P}$.

Now, define the \emph{mean embedding}:

\begin{equation*}
\mu[\mathbb{P}]: \begin{matrix}
        \mathcal{X}  &\rightarrow &\mathbb{R}\\
        x &\mapsto &\mathbb{E}_\mathbb{P} \big[ k(x,\cdot) \big]
        \end{matrix}
\end{equation*}
\clearpage	
\begin{fact}
	\begin{equation*}
		\forall f \in \mathcal{H} \quad \mathbb{E}_\mathbb{P} \big[ f(X) \big] = \langle f, \mu[\mathbb{P}]\rangle
	\end{equation*}
\end{fact}
That is, we can compute expectations with inner products.
\clearpage	
\begin{fact}
	\begin{equation*}
		\mu: \mathbb{P} \mapsto \mu[\mathbb{P}]
	\end{equation*}
	is an injective map.
	
	i.e.
	\begin{equation*}
		\mathbb{P}\ne\mathbb{Q} \Rightarrow \mu[\mathbb{P}] \ne \mu[\mathbb{Q}]
	\end{equation*}
	
	We will need this later on.
\end{fact}

\clearpage
Requirements:

	\begin{equation*}
		\mu: \mathbb{P} \mapsto \mu[\mathbb{P}]
	\end{equation*}
	is an injective map.\footnote{
		This does not hold for \emph{all} kernels.
		It holds for the Gaussian, which is enough for now.
	}
	
	i.e.
	\begin{equation*}
		\mathbb{P}\ne\mathbb{Q} \Rightarrow \mu[\mathbb{P}] \ne \mu[\mathbb{Q}]
	\end{equation*}
	
	We will need this later on.
	
	
\clearpage

\emph{todo bibliography}
\clearpage
% ===== special page ===========================================================
% ===== page with a background picture =========================================
%\ThisCenterWallPaper{1}{ETH_res/ETH_neutral.jpg}
\ThisCenterWallPaper{1}{ETH_neutral.jpg}
\textcolor{white}{ % change the text on the background picture to white
Discussion, results, conclusion 
}


%\ifoot{}% switch off the i-footer for this page used in ETH_res/ETH_settings.tex
\ifoot{}% switch off the i-footer for this page used in ETH_settings.tex
\clearpage
%% ===== page after a background picture page ==================================
%\ifoot{% switch on the i-footer for all following pages again
%	\hspace{-6.0mm}
%    \vspace{-8.5mm}
%	\begin{tikzpicture}[remember picture,overlay]
%		\node [xshift=\paperwidth/2,yshift=\footheight/2]
%%        {\includegraphics[width=\paperwidth]{ETH_res/ETH_footer.jpg}};
%        {\includegraphics[width=\paperwidth]{ETH_footer.jpg}};
%	\end{tikzpicture}
%}%
%
%% now on normal text again
%More discussion 

\end{document} 